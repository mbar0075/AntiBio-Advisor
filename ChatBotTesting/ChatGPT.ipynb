{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import sys\n",
    "\n",
    "# # Set your API key\n",
    "# openai.api_key = \"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\"\n",
    "#\"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\"\n",
    "\n",
    "# # Define the conversation\n",
    "# conversation = [\n",
    "#     # {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Can you tell me a joke?\"}\n",
    "#     # {\"role\": \"assistant\", \"content\": \"I'm not sure. Where are you located?\"}\n",
    "# ]\n",
    "\n",
    "# # Make the API call\n",
    "# response = openai.ChatCompletion.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=conversation\n",
    "# )\n",
    "\n",
    "# # Extract the assistant's reply\n",
    "# assistant_reply = response['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hi there! How can I assist you today?\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# add assisant section of conversation\n",
    "\n",
    "import openai\n",
    "import sys\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "userQueries = []\n",
    "\n",
    "while True:\n",
    "    userQueries.append(input())\n",
    "    print(userQueries[len(userQueries)-1])\n",
    "\n",
    "    # Define the conversation\n",
    "\n",
    "    conversation = []\n",
    "\n",
    "    for prompt in userQueries:\n",
    "        conversation.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    # Make the API call\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=conversation\n",
    "    )\n",
    "\n",
    "    # Extract the assistant's reply\n",
    "    print(response['choices'][0]['message']['content'])\n",
    "\n",
    "    if userQueries[len(userQueries)-1].lower() == \"exit\":\n",
    "        sys.exit(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response :::  {\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-xjYdDHwZOfQWV7K1ildvwC7j\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"filename\": \"file\",\n",
      "  \"bytes\": 956,\n",
      "  \"created_at\": 1697098555,\n",
      "  \"status\": \"uploaded\",\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key\n",
    "api_key = \"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\"\n",
    "openai.api_key = api_key\n",
    "\n",
    "def upload_file():\n",
    "    response = upload_file_to_openai()\n",
    "    print(\"response ::: \", response)\n",
    "\n",
    "def upload_file_to_openai():\n",
    "    with open(\"sample_json.txt\", \"rb\") as file:\n",
    "        response = openai.File.create(\n",
    "            file=file,\n",
    "            purpose=\"fine-tune\"\n",
    "        )\n",
    "    return response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    upload_file()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response :::  {\n",
      "  \"object\": \"fine-tune\",\n",
      "  \"id\": \"ft-NaldvollaFKWZg5TwAt5wfs3\",\n",
      "  \"hyperparams\": {\n",
      "    \"n_epochs\": 4,\n",
      "    \"batch_size\": null,\n",
      "    \"prompt_loss_weight\": 0.01,\n",
      "    \"learning_rate_multiplier\": null\n",
      "  },\n",
      "  \"organization_id\": \"org-itgWcRs1eipZqDGjocuvzPQO\",\n",
      "  \"model\": \"curie\",\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"object\": \"file\",\n",
      "      \"id\": \"file-dVWyBB7mHqkrYtAnil1s5z4h\",\n",
      "      \"purpose\": \"fine-tune\",\n",
      "      \"filename\": \"file\",\n",
      "      \"bytes\": 289,\n",
      "      \"created_at\": 1697004615,\n",
      "      \"status\": \"processed\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ],\n",
      "  \"validation_files\": [],\n",
      "  \"result_files\": [],\n",
      "  \"created_at\": 1697049827,\n",
      "  \"updated_at\": 1697049827,\n",
      "  \"status\": \"pending\",\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Created fine-tune: ft-NaldvollaFKWZg5TwAt5wfs3\",\n",
      "      \"created_at\": 1697049827\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key\n",
    "api_key = \"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\"\n",
    "openai.api_key = api_key\n",
    "\n",
    "def create_fine_tune():\n",
    "    response = openai.FineTune.create(\n",
    "        training_file=\"file-dVWyBB7mHqkrYtAnil1s5z4h\"\n",
    "    )\n",
    "    return response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    response = create_fine_tune()\n",
    "    print(\"response ::: \", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "al \\\\ A x\n",
      "\n",
      "_ MEDIFIRST\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To make it work first run the pip command then go to their github and run the 64bit .exe, take note of the saved path location and replace the path in the code below \n",
    "# pip install pytesseract\n",
    "# https://github.com/UB-Mannheim/tesseract/wiki\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "# Open an image using Pillow\n",
    "image = Image.open(\"../img4.jpg\")  \n",
    "\n",
    "# Use pytesseract to extract text from the image\n",
    "text = pytesseract.image_to_string(image, config='--psm 3')\n",
    "\n",
    "# # Print the extracted text\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatBot Testing custome model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n",
      "AD-L25 ;Store CAGE X coord in RAM with SF DATADR2-1,LO\n",
      "\n",
      "SHLDCPYA OR 6,0377 *BHRHLD-L25 ;Load CAGE PETALS\n",
      "What is happening?\n",
      " Why are computers named after 16th century mathematician and courtier Blaise Pascal? Are they named as a result of common family names or do they do so as a last minute decision? Why do Apple Macs get their own names, some of\n",
      "The ramblings of a mad man\n",
      ". You wouldn't understand. Please know this.\"\n",
      "\n",
      "\"I won't.\"\n",
      "\n",
      "He smiled, relieved. He was having a better reaction to her every minute. Help me Delko, he pleaded. Help me.\n",
      "\n",
      "\n",
      "* *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add assisant section of conversation\n",
    "\n",
    "import openai\n",
    "import sys\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "userQueries = []\n",
    "\n",
    "while True:\n",
    "    userQueries.append(input())\n",
    "    print(userQueries[len(userQueries)-1])\n",
    "\n",
    "    # Define the conversation\n",
    "\n",
    "    conversation = []\n",
    "\n",
    "    for prompt in userQueries:\n",
    "        conversation.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    # Make the API call\n",
    "    response = openai.Completion.create(\n",
    "        model=\"curie:ft-personal-2023-10-11-18-45-14\",\n",
    "        prompt = userQueries[len(userQueries)-1],\n",
    "        max_tokens = 50\n",
    "    )\n",
    "\n",
    "    # Extract the assistant's reply\n",
    "    print(response.choices[0].text)\n",
    "\n",
    "    if userQueries[len(userQueries)-1].lower() == \"exit\":\n",
    "        sys.exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
